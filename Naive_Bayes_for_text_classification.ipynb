{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PROBLEM 2: Naive Bayes for Text Classification**"
      ],
      "metadata": {
        "id": "-nndNDkyg1hk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To implement the Naive Bayes classifier with Laplace smoothing, we will follow the given steps:\n",
        "\n",
        "1. Load the trainSet, trainLabels, trainMap, testSet and testlabels data.\n",
        "\n",
        "2. Create Document Term Matrix for test data\n",
        "\n",
        "3. Create Document Tern matrix for train data\n",
        "\n",
        "In document term matrix, docid is represented by row, term id is represented by columns, count are the entries in the matrix. \n",
        "Algorithm: Take the max count for rows and colums to fix the shape of the matrix, then fill the data from Xtrain\n",
        "\n",
        "4. Then create a Multinomial Naive Bayes model with laplace smoothing i.e. function parameter alpha=1\n",
        "\n",
        "5. Fit the model in training data and calculate accuracy\n",
        "\n",
        "6. Predict test data using the generated model\n"
      ],
      "metadata": {
        "id": "kY23Pfo6g7TK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFL58Td5TzXu",
        "outputId": "e8ba47b5-548b-4ee5-8194-5dde83a28d40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xtrain=\n",
            "[[    1     1     4]\n",
            " [    1     2     2]\n",
            " [    1     3    10]\n",
            " ...\n",
            " [11269 48919     1]\n",
            " [11269 51544     1]\n",
            " [11269 53958     1]]\n",
            "trainMap=\n",
            "[['alt.atheism' '1']\n",
            " ['comp.graphics' '2']\n",
            " ['comp.os.ms-windows.misc' '3']\n",
            " ['comp.sys.ibm.pc.hardware' '4']\n",
            " ['comp.sys.mac.hardware' '5']\n",
            " ['comp.windows.x' '6']\n",
            " ['misc.forsale' '7']\n",
            " ['rec.autos' '8']\n",
            " ['rec.motorcycles' '9']\n",
            " ['rec.sport.baseball' '10']\n",
            " ['rec.sport.hockey' '11']\n",
            " ['sci.crypt' '12']\n",
            " ['sci.electronics' '13']\n",
            " ['sci.med' '14']\n",
            " ['sci.space' '15']\n",
            " ['soc.religion.christian' '16']\n",
            " ['talk.politics.guns' '17']\n",
            " ['talk.politics.mideast' '18']\n",
            " ['talk.politics.misc' '19']\n",
            " ['talk.religion.misc' '20']]\n",
            "Ytrain=\n",
            "[ 1  1  1 ... 20 20 20]\n",
            "Xtest=\n",
            "[[    1     3     1]\n",
            " [    1    10     1]\n",
            " [    1    12     8]\n",
            " ...\n",
            " [ 7505 50324     1]\n",
            " [ 7505 59935     1]\n",
            " [ 7505 61188     2]]\n",
            "Ytest=\n",
            "[[    1     3     1]\n",
            " [    1    10     1]\n",
            " [    1    12     8]\n",
            " ...\n",
            " [ 7505 50324     1]\n",
            " [ 7505 59935     1]\n",
            " [ 7505 61188     2]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "Xtrain = np.loadtxt(\"/content/train.data\", dtype=int)\n",
        "print(\"Xtrain=\")\n",
        "print(Xtrain)\n",
        "\n",
        "trainMap = np.loadtxt(\"/content/train.map\", dtype=str)\n",
        "print(\"trainMap=\")\n",
        "print(trainMap)\n",
        "\n",
        "Ytrain = np.loadtxt(\"/content/train.label\", dtype=int)\n",
        "print(\"Ytrain=\")\n",
        "print(Ytrain)\n",
        "\n",
        "Xtest = np.loadtxt(\"/content/test.data\", dtype=int)\n",
        "print(\"Xtest=\")\n",
        "print(Xtest)\n",
        "\n",
        "Ytest = np.loadtxt(\"/content/test.label\", dtype=int)\n",
        "print(\"Ytest=\")\n",
        "print(Xtest)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find maximum value for each column in testX\n",
        "col_max_vals_test = np.max(Xtest, axis=0)\n",
        "docs_count_max_test = col_max_vals_test[0]\n",
        "words_count_max_test = col_max_vals_test[1]\n",
        "\n",
        "# Initialize empty document-term matrix for test data\n",
        "document_term_matrix_test = np.zeros((docs_count_max_test, words_count_max_test))\n",
        "\n",
        "# Fill in the document-term matrix for test data using values from testX\n",
        "for docid,wordid,cnt in Xtest:\n",
        "    doc_index = docid - 1  # Subtract 1 to convert to 0-based indexing\n",
        "    word_index = wordid - 1  # Subtract 1 to convert to 0-based indexing\n",
        "    count = cnt\n",
        "    document_term_matrix_test[doc_index][word_index] = count\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HXL2r_66U5l_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "col_max_vals_train = np.max(Xtrain, axis = 0)\n",
        "docs_count_max_train = col_max_vals_train[0]\n",
        "words_count_max_train = col_max_vals_train[1]\n",
        "shape = (max(docs_count_max_train, docs_count_max_test), max(words_count_max_train, words_count_max_test))\n",
        "document_term_matrix_train = np.zeros(shape)\n",
        "\n",
        "\n",
        "# Fill in the document-term matrix for test data using values from testX\n",
        "for docid,wordid,cnt in Xtrain:\n",
        "    doc_index = docid - 1  # Subtract 1 to convert to 0-based indexing\n",
        "    word_index = wordid - 1  # Subtract 1 to convert to 0-based indexing\n",
        "    count = cnt\n",
        "    document_term_matrix_train[doc_index][word_index] = count\n"
      ],
      "metadata": {
        "id": "e7cUrl_mWFRp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Instantiate the Multinomial Naive Bayes model with alpha=1.0 i.e. Laplace smoothing\n",
        "nb = MultinomialNB(alpha=1.0)\n",
        "\n",
        "# Train the model using the training data and labels\n",
        "nb.fit(document_term_matrix_train, Ytrain)\n",
        "\n",
        "# Evaluate the model on the test data and labels\n",
        "accuracy = nb.score(document_term_matrix_test, Ytest)\n",
        "print(\"Accuracy: {:.6f}\".format(accuracy))\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = nb.predict(document_term_matrix_test)\n",
        "print(\"Predictions:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv00UdehXJ-z",
        "outputId": "19fd965b-058a-41f9-b81e-6f3277dbd68f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.781079\n",
            "Predictions: [ 1  1  1 ...  1 16  2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"Question2_op.txt\", \"w\") as f:\n",
        "  f.writelines('\\n'.join(str(val) for val in predictions))\n",
        "f.close()"
      ],
      "metadata": {
        "id": "izOGbKPYYDi_"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}